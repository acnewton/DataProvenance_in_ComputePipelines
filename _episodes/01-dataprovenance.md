---
title: "Difficulty with data provenance in compute pipelines"
teaching: 5
exercises: 0
questions:
- "What do you have to consider with data provenance in compute pipelines?"
objectives:
- "Explain what data provenance is in the context of compute pipelines"
- "Explain how programmatically addressing data is important in data provenance"
- "Explain why iRODS is an appropriate choice as storage solution for data provenance"
keypoints:
- "Data provenance is key for reproducibility in computations"
- "Extra metadata is necessary to capture data provenance"
- "in this tutorial we will be using iRODS Python API to address data programmatically"

---

## Data provenance shows the history of data
In data management the concept of data provenance is all about keeping the history of a data object managed.
In what state a data object is in is important information for reproducing that data object.
In more concrete terms, with proper data provenance of data objects you have the chance of finaly answering with confidence questions like "what script generated this plot?" or "who is responsible for creating the latest version of this dataset which still made any sense?".
Using version control systems for code, like Git, Mercurial or Subversion, the provenance of code is to some extent maintained. 
However, combining code with data is not supported by these systems.
In this lesson we will explore how this could be taken in to account with using storage solutions like iRODS.
![]({{ page.root }}/fig/phd101212s.gif)

## All steps need to be taken into account in a compute pipeline
In a data processing pipeline, there are multiple intermediate steps. 
Every step will generate different data objects, which all could have different versions based on being generated by different versions of your analysis scripts or simulation code. 
Therefore, to maintain data provenance it is critical to keep track of each step in the compute pipeline. 
To this end, it is useful to be able to programmatically access your data, i.e. via an API, so that these steps can be monitored via scripts instead of manual work. 
![]({{ page.root }}/fig/phd103003s.gif)


## Metadata is essential in recording data provenance
The provenance of data should be stored in a format which makes it obvious to which data it refers to. 
This seems obvious, but the link from the metadata to the data object can be quickly lost if you are not carefull. 
In this lesson we will make use of iRODS. iRODS makes it possible to add metadata directly to the data object itself. 
This metadata can then be viewed or queryed directly via the Python API of iRODS. 

## iRODS Python API can be used in compute pipelines
In summary, in this lesson we will be using iRODS to store our data, and we will be using the iRODS python API to do our data management and keep data provenance by accessing our data programmatically and adding metadata to our data objects. 
First we will cover basic data object and metadata handling of iRODS objects with the iRODS python API. 
Subsequently, we will demonstrate how these basic skills can be use in different compute pipelines. 

[The next episode]({{ page.root }}/02-iRODS_FileHandling/) covers how to do basic data object and metadata handling with the iRODS python API.

{% include links.md %}


